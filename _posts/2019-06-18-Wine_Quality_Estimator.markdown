---
layout: default
modal-id: 8
title: Wine Quality Estimator (Machine Learning)
date: 2019-06-18
img: wine.png
alt: image-alt
project-date: December 2018
description: <h2> Overview </h2> In todays day and age, everyone claims to know where to find the best wine! But who can you trust? Well, we decided to explore whether we could use a machine learning classification approach to distinguish a good wine from a bad one! <br><br> This project set out to use an established dataset of red and white wines (6497 wines to be exact) and create a model to predict a wine's quality. Each wine has 11 features from volatile acidity to alcohol content as well as a quality rating out of 10. Our approach detailed below was to treat this as a classification problem whereby wines in the range of 0-4 are bad, 5-6 are good and 7-10 are great! More detail, including the code used as well as the credit for the wine dataset used is available <a href=https://github.com/LeTo37/Wine_Quality_Estimator>here</a>.<br><h2> Approach </h2> As mentioned above, the approach we took was to treat this as a classification problem. This means we had to assign labels to the data of bad (0), good (1) or great (2) to each wine. The first step was reading, understanding and preprocessing the data to be ready for modeling. <h3>Data Handling</h3> In order to handle the data available, we used the pandas library. This allowed us to easily read and process each feature of each wine. We added a new column to the data to assign the labels described above. <h4>K Fold Cross Validation</h4> The next preprocessing step is to split the data into k equal data sets of folds. In this case we used k =3. This allows us to use 1 fold as a test set while the rest are used to train the data. This is done multiple times such that each fold is used as a test set. This is a great way to ensure accuracy of assessment of whatever model is used. <h3>Modelling</h3> Using the sklearn python library we were able to use a few model techniques that we thought were worth trying and assess which performed the best. We used and tested the following models<span>&#58; <ul><li>Gaussian Model</li><li>Logistic Regression</li><li>Decision Tree Classification</li><li>Random Forest Classification</li><li>K Nearest Neighbours Classification</li><li>Multilayer Perceptron Neural Network</li></ul> <br><h2> Conclusion </h2> We found that the best performing model turned out to be the RandomForest Classifier. Simpler models such as the GaussianNB and the Kneighbours did not perform so well. This was something we were unsurprised by due to the complexity of the data and difficulty in finding clear predictive features from visual inspection of the data. More complex models such as the RandomForest which performs implicit feature selection is able to better capture the data. <br> We also found that some features were helpful to the model and some were not at all. For example, alchohol content was a feature that linearly correlated to quality but density and ph value were entirely unrelated to quality. <br> <br> <h2> Video </h2> This project is further described by my project team-mate in the following video <br> <br> <div align="center"> <iframe width="630" height="385" src="https://www.youtube-nocookie.com/embed/-Rh84DiBa78" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> </div>

---
