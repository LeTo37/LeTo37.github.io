---
layout: default
modal-id: 5
title: Light Poles from a Point Cloud
date: 2019-06-20
img: poles.png
alt: image-alt
project-date: June 2019
description: <h2> Overview </h2> As part of a class I took on Geospatial Vision and Visualisation, me and my project team undertook a project focused on object detection from point cloud data. Specifically, we were looking to isolate light poles from point cloud data taken from a lidar of a general "street scene". <br>More information about this project can found on <a href=https://github.com/robo-jordo/Geospatial_vision_-_visualization/tree/master/Project target="_blank">this</a> github page in great detail including, code, point cloud data (both raw and refined), results as well as a <a href=img/Presentation_Slides.pdf target="_blank">presentation</a> on our approach to the problem.<br><br><h2>Methodology</h2> <ul><li>The open source Python library called Open3D was used to create point cloud objects as well as implementing segmentation and filtering.</li><li>The raw point cloud data was converted from  latitude-longitude-altitude (LLA)coordinates to cartesian (XYZ) coordinates.</li><li>The data was then filtered to find the pole. Explained more under "Algorithms" below.</li><li>The Python library Sklearn was used for the machine learning techniques applied.</li></ul> <br><h2> Algorithms</h2> <h3>Data Preprocessing</h3> As mentioned above, the first step of preprocessing is to have the data converted from LLA coordinates to XYZ coordinates. This allows for the data to be processed as and viewed as a 3D point cloud<span>&#58;<p align="center"> <img src="img/portfolio/3D_point_cloud_all.png" width="450"> </p> Next, the data is downsampled so as to reduce the amount of processing required. This is done by first applying a voxel grid filter which takes a spatial average of the data points within the given sized voxel (3D box). After that, a further filter is applied by removing the statiscal outliers left in the point cloud. This reduced the number of points to process from 1292208 to 39630 while the data remains accurate. The downsampled cloud is shown below<span>&#58;<p align="center"> <img src="img/portfolio/3D_point_cloud_downsampled.png" width="450"> </p> <h3>Finding the poles</h3> With the downsampled data, the next step is to distinguish which points belong to a pole and those that do not. A technique called <b>PLANAR FILTERING</b> was used. This process can be summarized as follows, points in the cloud are snapped to a grid. For each set of points that lie on a vertex of two dimensions - in this case the X-Y plane - the variation in the third dimension - Z axis - could be used to filter data points. This way points that vary in the z axis (above a certain height threshold) can be used to single out the poles. <br><br> The next step necessary to isolate the light poles is <b>CLUSTERING.</b> The initial clustering was done using k-means clustering. This clustering was done based on x and y coordinates. This k-means clustering is accompanied by a method known as the <a href=https://en.wikipedia.org/wiki/Elbow_method_(clustering) target="_blank">elbow method.</a> This was used to determine the number of clusters (poles) in the cloud.<br><br><h2> Result </h2> The picture below shows the resulting image after all the processing is done. It clearly only shows the light poles in the cloud. <p align="center"> <img src="img/portfolio/poles.png" width="450"> </p>

---

